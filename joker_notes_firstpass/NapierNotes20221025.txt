Napier: 10/25/2022

- Goals: RN v DS 
 
- Experimenters: Hisham, Luis

- Recording Start Time: 11 am
- Recording Stop Time:  12:30 pm

- xPC Model: Rig_main_Cortical_Parasite
- Recorded Array: Motor (Patient cable/cerebus)
- Data recorded: Spikes (250Hz highpass, RMS -4.5) + 2kSps 300-1000HzBPas continuous + *broadband*
- Drink: Apple Juice

- Params: 
	* Movement Mask: [0,1,0,1,0]
	* Target Hold Time (OL/CL): 750/500
	* Target Scaling(OL/CL): 100
	* Juice Time: 90/110
	* Trial Timeout: 5000
	* Auto Juice: 0
   	* Target Pos Style (OL/CL): 29
	* Visualization Style: MRP
	
-Decoders:
	NN0:
		monkey = 'Joker'
		date = '2022-10-25'
		run_train = 'Run-001'
		run_test = 'Run-002' #'Run-003'
		binsize = 32
		fingers = [2, 4]
		vel_redist = 'tri'
		normalize_x = False
		normalize_y = False
		norm_x_movavg_bins = None   # None, 60*32                # None, or [number of bins] in the neural moving average
		pred_type = 'v'

		iter 2500: val corr = [0.6104676680301396, 0.6082221475471925]
		Test Correlation:[0.6104676680301396, 0.6082221475471925]
		MSE:1.2662699222564697
		Epoch    24: reducing learning rate of group 0 to 2.5000e-05.
		*** model done improving based on scheduler ***
		Finger 0 RR Calculated Gain, Offset: 0.018619, -0.001666
		Finger 1 RR Calculated Gain, Offset: 0.013659, -0.003893
		decoder saved to: Z:/Data/Monkeys/Joker\2022-10-25\decodeParamsNN0.pkl

	DS: 
		TrainOnline_Cortical_DualStateDecoder('Joker','','Run-001',0,[2,4],32,[],good_chans_SBP)
	
	RN0:
		# Define Dataset Parameters
		monkey = 'Joker'
		date = '2022-10-25'
		run_train = 'Run-004'
		max_num_trials = 500
		train_test_split = 0.8
		run_test = 'Run-002' #'Run-003'
		is_refit = True                          # if true, only run_train is loaded, and training is limited to 500 iters
		refit_modelname = 'decodeParamsNN0.pkl'
		binsize = 32
		fingers = [2, 4]
		vel_redist = 'tri'
		normalize_x = False
		normalize_y = False
		norm_x_movavg_bins = None   # None, 60*32                # None, or [number of bins] in the neural moving average
		pred_type = 'v'
		
		iter 500: val corr = [0.5408032651875602, 0.5825708008285866]
		Test Correlation:[0.5408032651875602, 0.5825708008285866]
		MSE:1.0537983179092407
		*** model done - stopped at iteration 500 ***
		Finger 0 RR Calculated Gain, Offset: 0.011044, 0.000043
		Finger 1 RR Calculated Gain, Offset: 0.008432, 0.001251
		decoder saved to: Z:/Data/Monkeys/Joker\2022-10-25\decodeParamsNN1.pkl

-Runs:

	In '.../Monkeys/Test/2022-10-25':
	Run 1: Make sure everything is properly connected, targets display on vispc, etc.
	Run 2: Calibration and warmup
	Run 3: tried to start training run on joker, was still on test.
	
	In '.../Monkeys/Joker/2022-10-25':
	Run 1: TS29 HC - 400 Training Trials
	Run 2: TS29 HC - 100 Validation Trials
	
	Run 3: Incorrect bin size
	Run 4: TS29 NN0 - 250 Trials. ReFIT NN Training
	
	Run 5: TS29 RN0 - 150 trials
	Run 6: TS29 DS0 - 150 trials - took some time for threshold to stabilize (first 20 trials or so) - got biased and needed a restart
	Run 7: TS29 DS0 - biased again
	Run 8: TS29 DS0 - biased again. not sure why.
	Run 9: TS29 RN0 - 150 Trials. RN is also biasing towards flexion a bit around trial 135. still does hc tho, refreshing around 150 - going to 175. did it again. he stopped. don't know if motivation or decoder based. managed to get out of it around 162. stopped at 220
	
	
-Notes:
	things were slow to start today, xpc problems - model would not compile, had to restart xpc. things seems to be fine after that. some unexpected prompts but things are working. - after talking to dylan, probably only needed to do callbacks.
	
	first few runs were accidentally done on Test - due to testing to make sure xpc was working properly beforehand
	
	DS was off. Not sure why, what to do with this day. need to look through DS code as well as again make sure refit is training correctly on pybmi
	- using scheduler for nn training.
	
	noticing some juice artifacts on  - 2, 12, 32, 77, 79. none are in goodchans though 
	
	not sure if we can use today
	
	from 10/21 - added 80, 84
	good_chans_SBP = [1, 3, 4, 5, 7, 8, 9, 11, 13, 14, 15, 17, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 94, 96]



	












