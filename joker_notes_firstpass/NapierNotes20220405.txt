Napier: 03/25/2022

- Goals: KF/FNN/RNN
 
- Experiment: Joey, Eric

- Recording Start Time: 8:30 am
- Recording Stop Time:  10 am

- xPC Model: Rig_main_Cortical_Parasite
- Recorded Array: Motor (Patient Cable)
- Data recorded: Spikes (250Hz highpass, RMS -4.5) + 2kSps 300-1000HzBPas continuous
- Drink: Apple Juice

- Params: 
	* Movement Mask: [0,1,0,1,0]
	* Target Hold Time (OL/CL): 750/500
	* Target Scaling(OL/CL): 100
	* Juice Time: 100
	* Trial Timeout: 10000
	* Auto Juice: 0
   	* Target Pos Style (OL/CL): 29
	* Visualization Style: MRP
	
-Decoders:
	KF0: TrainOnline_Cortical_KalmanFilter_Multi('Joker','',3,false,[2,4],32,0,good_chans_SBP,good_chans_SBP,1,{'act_thresh',1},0,true);
		SBP KF correlation = 0.73592
			
	NN0: multilayer (standard sizes) with scheduler
		Test Correlation:[0.5374571086949387, 0.6184694782797895]
		RR gains around 0.7
		** This doesn't seem nearly as good - the LR might be too small

	NN1: GRU
		input_size = 96
		conv_size = 20
		hidden_size = 350
		num_states = 2
		num_layers = 2
		dropout_p = 0.3
		model_type = 'RNNDecoders.GRUModel'
		scaler_type = 'regression' 
		binsize = 32
		
		Test Correlation:[0.6537224976770222, 0.7811414114038031]
		RR gains around 1.2 (which seems high)
		
	NN2: LSTM
		Test Correlation:[0.6066570580149528, 0.7309008776911589]
		RR gains around 0.8,0.9
		
	NN3: Willseynet (with scheduler)
		Test Correlation:[0.5891858087363846, 0.6733035328909761]


	
-Runs:
	Run 1: Calibration
	Run 2: 200 warmup, 2min break
	Run 3: TS29 - 500 trials. #HC# BR~4.1
	~10 min Training Break~
	
	Run 4: TS29 - KF0 #KF# - start at trial 70. 120 online trials. BR~1.3. Decoder ok but not great. lots of overshooting
	Run 5: TS29 - NN3 #FNN#. 120 trials. BR~1.8. Pretty good but somewhat slow when making large movements. Kinda has to move fingers 1 at a time in some cases
	Run 6: TS29 - NN1 #GRU#. BR~1.7 (trial90-190). Initially gains were off and decoder wasn't usable. RR gains turned on at trial 40. Decoder is sometimes really fast, but then kinda gets stuck. Almost seems like he's not used to this kind of control. The slows are too slow - hard to make small/medium size adjustments. Otherwise looks very clean/controlled. Starting to figure it out at trial 80. When it works, looks a lot smoother than FNN
	Run 7: TS29 - NN2 #LSTM#. Index biased toward extend. Tried with/without RR scaling, but not working. MRP seems usable
	Run 8: TS29 - KF0 #KF#. 120 trials. BR~1.5
	Run 9: TS29 - NN3 #FNN#. 120 trials. BR~1.75
	Run 10: TS29 - NN1 #GRU#. 120 trials. BR~1.75. Not trying on some hard trials starting at 45
	
	Run 11: TS29 - some more hand control. #HC# giving up on some trials (is calibration off?)
	

-Notes:

	It's like the GRU learned the velocity profile too well, so it can stop and go fast, but moderate size adjustments are hard. But overall looks better than FNN. 

	He may be a lot more used to the FNN, so the RNNs aren't as intuitive to use and require more effort

	good_chans_SBP = [1:9,11,13,15,17,23,24,33,35,37:40,43,45:47,49:53,55:60,62,64,65,67:69,71:76,78:88,90:92,95,96];	
	
	
	
	
	
	
	