Napier: 08/19/2022

- Goals: NN debugging
 
- Experimenters: Hisham, Dylan

- Recording Start Time: 10:20 am
- Recording Stop Time:  12:30 pm

- xPC Model: Rig_main_Cortical_Parasite
- Recorded Array: Motor (Patient cable/cerebus)
- Data recorded: Spikes (250Hz highpass, RMS -4.5) + 2kSps 300-1000HzBPas continuous + broadband
- Drink: Apple Juice

- Params: 
	* Movement Mask: [0,1,0,1,0]
	* Target Hold Time (OL/CL): 750/500
	* Target Scaling(OL/CL): 100
	* Juice Time: 100
	* Trial Timeout: 10000
	* Auto Juice: 0
   	* Target Pos Style (OL/CL): 29
	* Visualization Style: MRP
	
-Decoders:	

NN0
	iter 3500: val corr = [0.6049262100084735, 0.6649253566999881]
	Test Correlation:[0.6049262100084735, 0.6649253566999881]
	MSE:0.3721586763858795
	*** model done - stopped at iteration 3500 ***
	Finger 0 RR Calculated Gain, Offset: 0.049649, -0.000602
	Finger 1 RR Calculated Gain, Offset: 0.034825, 0.001663
	decoder saved to: Z:/Data/Monkeys/Joker\2022-08-19\decodeParamsNN0.pkl
	
NN1
	iter 2900: val corr = [0.5920659982290157, 0.6727973684654805]
	Test Correlation:[0.5920659982290157, 0.6727973684654805]
	MSE:0.30553990602493286
	Epoch    28: reducing learning rate of group 0 to 2.5000e-05.
	*** model done improving based on scheduler ***
	Finger 0 RR Calculated Gain, Offset: 0.051160, -0.006783
	Finger 1 RR Calculated Gain, Offset: 0.041186, 0.001751
	decoder saved to: Z:/Data/Monkeys/Joker\2022-08-19\decodeParamsNN1.pkl

NN2
	iter 2300: val corr = [0.5550875674997839, 0.6349573891937814]
	Test Correlation:[0.5550875674997839, 0.6349573891937814]
	MSE:0.31389763951301575
	Epoch    22: reducing learning rate of group 0 to 2.5000e-05.
	*** model done improving based on scheduler ***
	decoder saved to: Z:/Data/Monkeys/Joker\2022-08-19\decodeParamsNN2.pkl

NN3
	iter 3500: val corr = [0.506937850477811, 0.5968829128744323]
	Test Correlation:[0.506937850477811, 0.5968829128744323]
	MSE:0.4089086055755615
	*** model done - stopped at iteration 3500 ***
	decoder saved to: Z:/Data/Monkeys/Joker\2022-08-19\decodeParamsNN3.pkl

NN4
	iter 3500: val corr = [0.5155156425890189, 0.5908369239315645]
	Test Correlation:[0.5155156425890189, 0.5908369239315645]
	MSE:0.4930577278137207
	*** model done - stopped at iteration 3500 ***
	decoder saved to: Z:/Data/Monkeys/Joker\2022-08-19\decodeParamsNN4.pkl

-Runs:
	Run 1: calibration + 150-200 warm-up followerd by 5 minute break
	Run 2: 400 Training - TS29
	Run 3: 100 Validation - TS29
	
	Run 4: NN0 TS29 - Seems to struggle in first 10-20. Is trying but also can bias to flexion quickly and he stops moving until next trial. Stopped at 34. Maybe overfitting? Going to try training with scheduler.
	Run 5: NN1 TS29 - Did not start even hand contorl immediately. Kind of trying to use new network. Still really biased towards flexion
	Run 6: NN2 Ts29 - Trying peak scaling network. Still gets stuck in flexion. Observed to move fingers when target switches through camera, virtual fingers move a little and then go back to flexion.
	Run 7/8: debug
	Run 9: 32 ms network, 3500 iters, peak scaling. Still flex biased.
	
	Run 10: Stopped - incorrect hold time
	Run 11: 400 Training - TS29
	Run 12: 100 Validation. For network training, removing 79, 80, 85 they were fairly noisy before.
	
	Run 13: Debug
	Run 14: NN4 - Trying with removed channels. Still getting stuck in flexion.
	Run 15. NN4 - Thought EMA might be changing something, but shouldnt be affecting decode if normalize isnt on.
	Run 16. NN4 - TS 29 THINK PROBLEM FOUND. - Scaler line was correct on brainiac, but wrong on parasite. y = m(x+b) instead of y = mx + b. doing 500 Trials BR ~1.5-1.6 at 190, ~1.75 at 380
-Notes:
	Make sure code is all up to date
	
	From 8/3/22:
	good_chans_SBP = [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 15, 17, 23, 24, 33, 35, 37, 38, 39, 40, 43, 45, 46, 47, 49, 50,
                51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 78, 79,
                80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 95, 96]
				
	(after run 11)
	good_chans_SBP = [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 15, 17, 23, 24, 33, 35, 37, 38, 39, 40, 43, 45, 46, 47, 49, 50,
                51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 78, 81, 82, 83, 84, 86, 87, 88, 90, 91, 92, 95, 96]
				