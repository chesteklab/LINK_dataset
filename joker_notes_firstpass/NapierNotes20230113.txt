Napier: 1/13/2023

- Goals: KalmanNet debugging
 
- Experimenters: Luis, Maddi

- Recording Start Time: 8:30 am
- Recording Stop Time:  11:30 am

- xPC Model: Rig_main_Cortical_Parasite_v2
- Recorded Array: Motor (Patient cable/cerebus)
- Data recorded: Spikes (250Hz highpass, RMS -4.5) + 2kSps 300-1000HzBPas continuous 
- Drink: Apple Juice

- Params: 
	* Movement Mask: [0,1,0,1,0]
	* Target Hold Time (OL/CL): 750/500
	* Target Scaling(OL/CL): 100
	* Juice Time: 80
	* Trial Timeout: 5000
	* Auto Juice: 0
   	* Target Pos Style (OL/CL): 29, 35
	* Visualization Style: MRP
	
-Decoders:
	KFN0: regular kalman filter
		[0.63,0.78,0.36,0.40]
	KNet0: Kalman net (9:40 model), linear model, no normalization, scaled loss. Trained on Run 1.
	KNet1: KalmanNet, linear model, no normalization, scaled loss. Trained on Run 3
	KNet2: KalmanNet linear model, no norm, scaled loss, trained on run 2.
	
	KF0: TrainOnline_Cortical_KalmanFilter_Multi('Joker','',2,false,[2,4],50,0,good_chans_SBP,good_chans_SBP,1,{'act_thresh',1},0,true);
		Trained with regular code
		SBP KF correlation = 0.83824
		SBP KF lag = 1


-Runs:
	Run 1: TS35 500 trials. Calibration was done in the Test monkey
	Run 2: TS29 500 trials.
	Run 3: TS31 (2D maxes only) 500 trials
	--- KFN0
	Run 4: Failed, different binsizes between parasite and xpc
	Run 5: messed up the beginning
	Run 6: TS35 Had the beta too low (0.8), wasn't moving properly
	Run 7: TS35 beta=0.98. Didn't move much at the beginning. Changed beta to 0.9 and it started moving. Bitrate low, at 1.2. It went further down, to 0.9.
	--- KNet0
	Run 8: TS35. Started with beta=0.8, wasn't good, but it was moving! I manually scaled the velocities by 20 and set the beta to 0.95 and it works better. It can at least reach some targets. Didn't do well in general though. It did solve the problem of bias that I had last time. It was kinda stuck in the middle though.
	-- KNet1
	Run 9: TS35. beta=0.9. Stuck in the middle in general, only gets the targets in the center. 
	-- KNet2
	Run 10: TS35, beta=0.9. This model performs considerably better than the other two.
	Run 11: same, not performing that much better
	-- KF0:
	Run 12: trying the regularly trained kalman filter. Failed after a little while
	Run 13: trying it again. Didn't manage to have the KF running, just hand control for most of it.


Summary:
	- Removing the normalization from the network solved the bias issue, but didn't make the network perform well.
	- Generally all performances were wrong
	- The velocities were still generally low


TODO:
	- 


Notes:
	- Binsize and conv size in the arguments of Simulink comments shouldn't have mattered during the last experiment, as those are loaded in with the model
	- Velocities are slow in the regular Kalman Filter, I have to use a beta of at least 0.90 so that it moves. There has to be something wrong with the scaling, I think.
	- The normalization problem played a huge role: that was what was causing the biases I saw on the previous experiment. Now it doesn't get biased, but it doesn't move very well either. The scale of the velocities is affecting everything again.
	- Seems to be a better strategy to train the model in the random targets: it tends to do better in the other target styles.
	
	good_chans_SBP = [1, 3, 4, 5, 7, 8, 9, 11, 14, 15, 17, 20, 22, 23, 24, 25, 26, 28, 29, 31, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 78, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 94, 96];
	
	


