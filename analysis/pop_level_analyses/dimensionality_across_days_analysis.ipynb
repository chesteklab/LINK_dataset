{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do some imports first ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.signal import savgol_filter\n",
    "import glob\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "#some basic text parameters for figures\n",
    "mpl.rcParams['font.family'] = \"Atkinson Hyperlegible\" # if installed but not showing up, rebuild mpl cache\n",
    "mpl.rcParams['font.size'] = 10\n",
    "mpl.rcParams['savefig.format'] = 'pdf'\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "mpl.rcParams['axes.titlesize'] = 14\n",
    "mpl.rcParams['axes.labelsize'] = 12\n",
    "mpl.rcParams['axes.titlelocation'] = 'center'\n",
    "mpl.rcParams['axes.titleweight'] = 'bold'\n",
    "mpl.rcParams['figure.constrained_layout.use'] = True\n",
    "mpl.rcParams['figure.titlesize'] = 14\n",
    "mpl.rcParams['figure.titleweight'] = 'bold'\n",
    "mpl.rcParams['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/riopar/.local/share/fonts/Atkinson-Hyperlegible-Regular-102.ttf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m font_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/riopar/.local/share/fonts/Atkinson-Hyperlegible-Regular-102.ttf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Register it\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mfm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfontManager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddfont\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfont_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m prop \u001b[38;5;241m=\u001b[39m fm\u001b[38;5;241m.\u001b[39mFontProperties(fname\u001b[38;5;241m=\u001b[39mfont_path)\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfont.family\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m prop\u001b[38;5;241m.\u001b[39mget_name()\n",
      "File \u001b[1;32mc:\\Files\\UM\\ND\\github\\big_nhp_dataset_code\\.venv\\Lib\\site-packages\\matplotlib\\font_manager.py:1136\u001b[0m, in \u001b[0;36mFontManager.addfont\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafmlist\u001b[38;5;241m.\u001b[39mappend(prop)\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1136\u001b[0m     font \u001b[38;5;241m=\u001b[39m \u001b[43mft2font\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFT2Font\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1137\u001b[0m     prop \u001b[38;5;241m=\u001b[39m ttfFontProperty(font)\n\u001b[0;32m   1138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mttflist\u001b[38;5;241m.\u001b[39mappend(prop)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/riopar/.local/share/fonts/Atkinson-Hyperlegible-Regular-102.ttf'"
     ]
    }
   ],
   "source": [
    "# import matplotlib.font_manager as fm\n",
    "# font_path = \"/home/riopar/.local/share/fonts/Atkinson-Hyperlegible-Regular-102.ttf\"\n",
    "\n",
    "# # Register it\n",
    "# fm.fontManager.addfont(font_path)\n",
    "# prop = fm.FontProperties(fname=font_path)\n",
    "# plt.rcParams['font.family'] = prop.get_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we want to load the dataset \n",
    "\n",
    "What we are interested in here is the SBP and Threshold Crossings Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from population_level_analyses import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Files\\UM\\ND\\github\\big_nhp_dataset_code\\analysis\\pop_level_analyses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing datasets: 100%|██████████| 303/303 [00:07<00:00, 42.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# mpath = path = os.path.join(\"..\", \"..\",\"..\", \"AdaptiveAlignment\", \"data\", \"hisham_current\", 'preprocessing_092024_no7822nofalcon')\n",
    "# results = load_all_datasets(mpath )\n",
    "mpath = os.path.join(\"..\", \"..\",\"..\", \"AdaptiveAlignment\", \"data\", \"hisham_good_days\")\n",
    "data_path = \"C:\\\\Files\\\\UM\\\\ND\\\\SFN\\\\only_good_days\"\n",
    "mpath = data_path\n",
    "results = load_all_datasets(mpath, 303)\n",
    "\n",
    "### LOAD AND PREPROCESS DATA ###\n",
    "df_tuning = prepare_tuning_data(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets look at some dimensionality of our data.\n",
    "\n",
    "First, we want to calculate how the components needed to explain 80% of the variance (using PCA) changes over time. To do this, we first need to do PCA and calculate the cumulative variance over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_results = day_by_day_PCA(df_tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,lets plot and see what we get. You'll notice that the components decrease when the data was weird (summer of 2022), but the general trend is a slight increase over time (though there does seem to be more variance as time goes on as well)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of looking at the same data is to break it down into quarters and visualize it on different axes. The same patterns hold here though (as it is the same data). It does seem easier to see here that while over time there is a slight increase in # of components needed for 80%, its not that drastic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explained_var_over_time(df_tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA of Reach Directions\n",
    "\n",
    "One other cool thing we can do is take a look at our Center Out (CO) tasks, and look at how the dimensionality of the reach directions is changing with time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets:   0%|          | 0/303 [00:24<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only length-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_avg_trajectories\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_tuning\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_of_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msbps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_by\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrim_method\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrim_neural_data_at_movement_onset_std_and_smooth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrim_pt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_jerk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myears_to_skip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2021\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2022\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mext_flex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_RT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Files\\UM\\ND\\github\\big_nhp_dataset_code\\analysis\\pop_level_analyses\\population_level_analyses.py:1327\u001b[0m, in \u001b[0;36mplot_avg_trajectories\u001b[1;34m(df_tuning, type_of_data, group_by, display_alignment, directions, trim_method, trim_pt, years_to_skip, sigma, remove_RT)\u001b[0m\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, time_period \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(time_periods): \n\u001b[0;32m   1325\u001b[0m     color_dict[\u001b[38;5;28mstr\u001b[39m(time_period)] \u001b[38;5;241m=\u001b[39m colors[i]\n\u001b[1;32m-> 1327\u001b[0m neural_data_for_direction, _ \u001b[38;5;241m=\u001b[39m \u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_periods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_periods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_of_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_of_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkinematic_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_map\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_CO\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_RT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1329\u001b[0m processed_neural_data_for_direction, kinematics_data \u001b[38;5;241m=\u001b[39m trim_method(neural_data_for_direction, std_multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, sigma\u001b[38;5;241m=\u001b[39msigma, display_alignment\u001b[38;5;241m=\u001b[39mdisplay_alignment, trim_pt \u001b[38;5;241m=\u001b[39m trim_pt, direction_key \u001b[38;5;241m=\u001b[39m direction_key)\n\u001b[0;32m   1331\u001b[0m averaged_pca_results, averaged_kin_results \u001b[38;5;241m=\u001b[39m average_trial_PCA_data(dir_list\u001b[38;5;241m=\u001b[39mdir_list, kinematics\u001b[38;5;241m=\u001b[39mkinematics_data, processed_neural_data_for_direction\u001b[38;5;241m=\u001b[39mprocessed_neural_data_for_direction)\n",
      "File \u001b[1;32mc:\\Files\\UM\\ND\\github\\big_nhp_dataset_code\\analysis\\pop_level_analyses\\population_level_analyses.py:1088\u001b[0m, in \u001b[0;36msplit\u001b[1;34m(df_time, time_periods, position_map, type_of_data, jpca, kinematic_type, only_CO)\u001b[0m\n\u001b[0;32m   1085\u001b[0m trial_length \u001b[38;5;241m=\u001b[39m yearly_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrial_counts\u001b[39m\u001b[38;5;124m'\u001b[39m][i]\n\u001b[0;32m   1087\u001b[0m target_pos_coords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(yearly_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_positions\u001b[39m\u001b[38;5;124m'\u001b[39m][i])\n\u001b[1;32m-> 1088\u001b[0m target_pos_coords \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtarget_pos_coords\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mfloat\u001b[39m(target_pos_coords[\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_pos_coords \u001b[38;5;129;01min\u001b[39;00m position_map: \u001b[38;5;66;03m# skips (0.5, 0.5)\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m     target_pos \u001b[38;5;241m=\u001b[39m position_map[target_pos_coords]\n",
      "\u001b[1;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "plot_avg_trajectories(df_tuning, type_of_data='sbps', group_by = 'year', trim_method = trim_neural_data_at_movement_onset_std_and_smooth, trim_pt = max_jerk, sigma = .5, years_to_skip=[2021, 2022], directions='ext_flex', remove_RT=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made trial classes\n",
      "(7484726, 96)\n",
      "Grouped Data\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only length-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot_centroid_of_pca_data_across_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_tuning\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_by\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquarter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_RT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalization_method\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myears_to_skip\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_centr_across_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Files\\UM\\ND\\github\\big_nhp_dataset_code\\analysis\\pop_level_analyses\\population_level_analyses.py:1295\u001b[0m, in \u001b[0;36mplot_centroid_of_pca_data_across_time\u001b[1;34m(df_tuning, n_components, dpca, group_by, years_to_skip, data_type, remove_RT, directions, trim_pt, trim_method, PART_TO_PLOT, normalization_method, pca_all, plot_centr_across_time, sigma)\u001b[0m\n\u001b[0;32m   1292\u001b[0m     color_dict[\u001b[38;5;28mstr\u001b[39m(time_period)] \u001b[38;5;241m=\u001b[39m colors[i]\n\u001b[0;32m   1294\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrouped Data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1295\u001b[0m neural_data_for_direction, day_centroids \u001b[38;5;241m=\u001b[39m \u001b[43msplit_and_pca_all_trials\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_periods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_periods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_of_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkinematic_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_map\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpca_all\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpca_all\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plot_centr_across_time:\n\u001b[0;32m   1298\u001b[0m     centroids_across_time(averaged_pca_results\u001b[38;5;241m=\u001b[39mneural_data_for_direction, time_periods\u001b[38;5;241m=\u001b[39mtime_periods, color_dict\u001b[38;5;241m=\u001b[39mcolor_dict, label \u001b[38;5;241m=\u001b[39m label, PART_TO_PLOT\u001b[38;5;241m=\u001b[39mPART_TO_PLOT, cmap \u001b[38;5;241m=\u001b[39m cmap, norm \u001b[38;5;241m=\u001b[39m norm, radius \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m, day_centroids \u001b[38;5;241m=\u001b[39m day_centroids)\n",
      "File \u001b[1;32mc:\\Files\\UM\\ND\\github\\big_nhp_dataset_code\\analysis\\pop_level_analyses\\population_level_analyses.py:1208\u001b[0m, in \u001b[0;36msplit_and_pca_all_trials\u001b[1;34m(df_time, time_periods, type_of_data, position_map, kinematic_type, n_components, pca_all)\u001b[0m\n\u001b[0;32m   1205\u001b[0m channel_pca_sbps \u001b[38;5;241m=\u001b[39m day_pca_results[trial_index_start:trial_index_start\u001b[38;5;241m+\u001b[39mtrial_length] \n\u001b[0;32m   1207\u001b[0m target_pos_coords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(yearly_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_positions\u001b[39m\u001b[38;5;124m'\u001b[39m][i])\n\u001b[1;32m-> 1208\u001b[0m target_pos_coords \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mfloat\u001b[39m(target_pos_coords[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mfloat\u001b[39m(target_pos_coords[\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_pos_coords \u001b[38;5;129;01min\u001b[39;00m position_map:\n\u001b[0;32m   1211\u001b[0m     target_pos \u001b[38;5;241m=\u001b[39m position_map[target_pos_coords]\n",
      "\u001b[1;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "plot_centroid_of_pca_data_across_time(df_tuning, group_by='quarter', remove_RT=False, normalization_method = 'all', years_to_skip = [], plot_centr_across_time=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
